{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用sklearning决策树工具对watermelon数据进行分类训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['color', 'density', 'knocks', 'navel', 'root', 'sugar_ratio', 'texture', 'touch']\n",
      "{'dark_green', 'black', 'light_white'}\n",
      "3\n",
      "{'little_curl_up', 'stiff', 'curl_up'}\n",
      "3\n",
      "{'heavily', 'little_heavily', 'clear'}\n",
      "3\n",
      "{'blur', 'little_blur', 'distinct'}\n",
      "3\n",
      "{'little_sinking', 'even', 'sinking'}\n",
      "3\n",
      "{'soft_stick', 'hard_smooth'}\n",
      "2\n",
      "{'0.556', '0.36', '0.593', '0.697', '0.657', '0.437', '0.343', '0.634', '0.403', '0.481', '0.608', '0.245', '0.639', '0.774', '0.719', '0.666', '0.243'}\n",
      "17\n",
      "{'0.149', '0.042', '0.103', '0.237', '0.198', '0.264', '0.057', '0.376', '0.318', '0.161', '0.215', '0.37', '0.267', '0.091', '0.211', '0.46', '0.099'}\n",
      "17\n",
      "[{'navel': 'sinking', 'touch': 'hard_smooth', 'density': 0.697, 'texture': 'distinct', 'root': 'curl_up', 'knocks': 'little_heavily', 'sugar_ratio': 0.46, 'color': 'dark_green'}, {'navel': 'sinking', 'touch': 'hard_smooth', 'density': 0.774, 'texture': 'distinct', 'root': 'curl_up', 'knocks': 'heavily', 'sugar_ratio': 0.376, 'color': 'black'}, {'navel': 'sinking', 'touch': 'hard_smooth', 'density': 0.634, 'texture': 'distinct', 'root': 'curl_up', 'knocks': 'little_heavily', 'sugar_ratio': 0.264, 'color': 'black'}, {'navel': 'sinking', 'touch': 'hard_smooth', 'density': 0.608, 'texture': 'distinct', 'root': 'curl_up', 'knocks': 'heavily', 'sugar_ratio': 0.318, 'color': 'dark_green'}, {'navel': 'sinking', 'touch': 'hard_smooth', 'density': 0.556, 'texture': 'distinct', 'root': 'curl_up', 'knocks': 'little_heavily', 'sugar_ratio': 0.215, 'color': 'light_white'}, {'navel': 'little_sinking', 'touch': 'soft_stick', 'density': 0.403, 'texture': 'distinct', 'root': 'little_curl_up', 'knocks': 'little_heavily', 'sugar_ratio': 0.237, 'color': 'dark_green'}, {'navel': 'little_sinking', 'touch': 'soft_stick', 'density': 0.481, 'texture': 'little_blur', 'root': 'little_curl_up', 'knocks': 'little_heavily', 'sugar_ratio': 0.149, 'color': 'black'}, {'navel': 'little_sinking', 'touch': 'hard_smooth', 'density': 0.437, 'texture': 'distinct', 'root': 'little_curl_up', 'knocks': 'little_heavily', 'sugar_ratio': 0.211, 'color': 'black'}, {'navel': 'little_sinking', 'touch': 'hard_smooth', 'density': 0.666, 'texture': 'little_blur', 'root': 'little_curl_up', 'knocks': 'heavily', 'sugar_ratio': 0.091, 'color': 'black'}, {'navel': 'even', 'touch': 'soft_stick', 'density': 0.243, 'texture': 'distinct', 'root': 'stiff', 'knocks': 'clear', 'sugar_ratio': 0.267, 'color': 'dark_green'}, {'navel': 'even', 'touch': 'hard_smooth', 'density': 0.245, 'texture': 'blur', 'root': 'stiff', 'knocks': 'clear', 'sugar_ratio': 0.057, 'color': 'light_white'}, {'navel': 'even', 'touch': 'soft_stick', 'density': 0.343, 'texture': 'blur', 'root': 'curl_up', 'knocks': 'little_heavily', 'sugar_ratio': 0.099, 'color': 'light_white'}, {'navel': 'sinking', 'touch': 'hard_smooth', 'density': 0.639, 'texture': 'little_blur', 'root': 'little_curl_up', 'knocks': 'little_heavily', 'sugar_ratio': 0.161, 'color': 'dark_green'}, {'navel': 'sinking', 'touch': 'hard_smooth', 'density': 0.657, 'texture': 'little_blur', 'root': 'little_curl_up', 'knocks': 'heavily', 'sugar_ratio': 0.198, 'color': 'light_white'}, {'navel': 'little_sinking', 'touch': 'soft_stick', 'density': 0.36, 'texture': 'distinct', 'root': 'little_curl_up', 'knocks': 'little_heavily', 'sugar_ratio': 0.37, 'color': 'black'}, {'navel': 'even', 'touch': 'hard_smooth', 'density': 0.593, 'texture': 'blur', 'root': 'curl_up', 'knocks': 'little_heavily', 'sugar_ratio': 0.042, 'color': 'light_white'}, {'navel': 'little_sinking', 'touch': 'hard_smooth', 'density': 0.719, 'texture': 'little_blur', 'root': 'curl_up', 'knocks': 'heavily', 'sugar_ratio': 0.103, 'color': 'dark_green'}]\n",
      "[[0.    1.    0.    0.697 0.    0.    1.    0.    0.    1.    1.    0.\n",
      "  0.    0.46  0.    1.    0.    1.    0.   ]\n",
      " [1.    0.    0.    0.774 0.    1.    0.    0.    0.    1.    1.    0.\n",
      "  0.    0.376 0.    1.    0.    1.    0.   ]\n",
      " [1.    0.    0.    0.634 0.    0.    1.    0.    0.    1.    1.    0.\n",
      "  0.    0.264 0.    1.    0.    1.    0.   ]\n",
      " [0.    1.    0.    0.608 0.    1.    0.    0.    0.    1.    1.    0.\n",
      "  0.    0.318 0.    1.    0.    1.    0.   ]\n",
      " [0.    0.    1.    0.556 0.    0.    1.    0.    0.    1.    1.    0.\n",
      "  0.    0.215 0.    1.    0.    1.    0.   ]\n",
      " [0.    1.    0.    0.403 0.    0.    1.    0.    1.    0.    0.    1.\n",
      "  0.    0.237 0.    1.    0.    0.    1.   ]\n",
      " [1.    0.    0.    0.481 0.    0.    1.    0.    1.    0.    0.    1.\n",
      "  0.    0.149 0.    0.    1.    0.    1.   ]\n",
      " [1.    0.    0.    0.437 0.    0.    1.    0.    1.    0.    0.    1.\n",
      "  0.    0.211 0.    1.    0.    1.    0.   ]\n",
      " [1.    0.    0.    0.666 0.    1.    0.    0.    1.    0.    0.    1.\n",
      "  0.    0.091 0.    0.    1.    1.    0.   ]\n",
      " [0.    1.    0.    0.243 1.    0.    0.    1.    0.    0.    0.    0.\n",
      "  1.    0.267 0.    1.    0.    0.    1.   ]\n",
      " [0.    0.    1.    0.245 1.    0.    0.    1.    0.    0.    0.    0.\n",
      "  1.    0.057 1.    0.    0.    1.    0.   ]\n",
      " [0.    0.    1.    0.343 0.    0.    1.    1.    0.    0.    1.    0.\n",
      "  0.    0.099 1.    0.    0.    0.    1.   ]\n",
      " [0.    1.    0.    0.639 0.    0.    1.    0.    0.    1.    0.    1.\n",
      "  0.    0.161 0.    0.    1.    1.    0.   ]\n",
      " [0.    0.    1.    0.657 0.    1.    0.    0.    0.    1.    0.    1.\n",
      "  0.    0.198 0.    0.    1.    1.    0.   ]\n",
      " [1.    0.    0.    0.36  0.    0.    1.    0.    1.    0.    0.    1.\n",
      "  0.    0.37  0.    1.    0.    0.    1.   ]\n",
      " [0.    0.    1.    0.593 0.    0.    1.    1.    0.    0.    1.    0.\n",
      "  0.    0.042 1.    0.    0.    1.    0.   ]\n",
      " [0.    1.    0.    0.719 0.    1.    0.    0.    1.    0.    1.    0.\n",
      "  0.    0.103 0.    0.    1.    1.    0.   ]]\n",
      "['1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "['dark_green', 'little_heavily', 'sinking', 'curl_up', 'distinct', 'hard_smooth']\n",
      "['010', '001', '001', '100', '010', '10']\n",
      "['black', 'heavily', 'sinking', 'curl_up', 'distinct', 'hard_smooth']\n",
      "['100', '010', '001', '100', '010', '10']\n",
      "['black', 'little_heavily', 'sinking', 'curl_up', 'distinct', 'hard_smooth']\n",
      "['100', '001', '001', '100', '010', '10']\n",
      "['dark_green', 'heavily', 'sinking', 'curl_up', 'distinct', 'hard_smooth']\n",
      "['010', '010', '001', '100', '010', '10']\n",
      "['light_white', 'little_heavily', 'sinking', 'curl_up', 'distinct', 'hard_smooth']\n",
      "['001', '001', '001', '100', '010', '10']\n",
      "['dark_green', 'little_heavily', 'little_sinking', 'little_curl_up', 'distinct', 'soft_stick']\n",
      "['010', '001', '010', '010', '010', '01']\n",
      "['black', 'little_heavily', 'little_sinking', 'little_curl_up', 'little_blur', 'soft_stick']\n",
      "['100', '001', '010', '010', '001', '01']\n",
      "['black', 'little_heavily', 'little_sinking', 'little_curl_up', 'distinct', 'hard_smooth']\n",
      "['100', '001', '010', '010', '010', '10']\n",
      "['black', 'heavily', 'little_sinking', 'little_curl_up', 'little_blur', 'hard_smooth']\n",
      "['100', '010', '010', '010', '001', '10']\n",
      "['dark_green', 'clear', 'even', 'stiff', 'distinct', 'soft_stick']\n",
      "['010', '100', '100', '001', '010', '01']\n",
      "['light_white', 'clear', 'even', 'stiff', 'blur', 'hard_smooth']\n",
      "['001', '100', '100', '001', '100', '10']\n",
      "['light_white', 'little_heavily', 'even', 'curl_up', 'blur', 'soft_stick']\n",
      "['001', '001', '100', '100', '100', '01']\n",
      "['dark_green', 'little_heavily', 'sinking', 'little_curl_up', 'little_blur', 'hard_smooth']\n",
      "['010', '001', '001', '010', '001', '10']\n",
      "['light_white', 'heavily', 'sinking', 'little_curl_up', 'little_blur', 'hard_smooth']\n",
      "['001', '010', '001', '010', '001', '10']\n",
      "['black', 'little_heavily', 'little_sinking', 'little_curl_up', 'distinct', 'soft_stick']\n",
      "['100', '001', '010', '010', '010', '01']\n",
      "['light_white', 'little_heavily', 'even', 'curl_up', 'blur', 'hard_smooth']\n",
      "['001', '001', '100', '100', '100', '10']\n",
      "['dark_green', 'heavily', 'little_sinking', 'curl_up', 'little_blur', 'hard_smooth']\n",
      "['010', '010', '010', '100', '001', '10']\n",
      "color\n",
      "[['dark_green', '010'], ['black', '100'], ['light_white', '001']]\n",
      "knocks\n",
      "[['little_heavily', '001'], ['heavily', '010'], ['clear', '100']]\n",
      "navel\n",
      "[['sinking', '001'], ['little_sinking', '010'], ['even', '100']]\n",
      "root\n",
      "[['curl_up', '100'], ['little_curl_up', '010'], ['stiff', '001']]\n",
      "texture\n",
      "[['distinct', '010'], ['little_blur', '001'], ['blur', '100']]\n",
      "touch\n",
      "[['hard_smooth', '10'], ['soft_stick', '01']]\n",
      "训练模型clf： DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
      "            splitter='best')\n",
      "['0']\n",
      "[[1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "\n",
    "wame_data = open('watermelon_4_3.csv','rt')     ##打开一个IO file对象\n",
    "reader = csv.reader(wame_data)                  #file对象wame_data作为参数传递给csv.reader方法，获得一个csv.reader对象\n",
    "#print(reader)\n",
    "\n",
    "#读取表头\n",
    "headers = next(reader)                      \n",
    "#print(headers)\n",
    "headers1 = sorted(headers[1:-1])        \n",
    "#查看特征名称排序后的情况，后续会用到DictVectorizer函数功能会把字符型特征进行编码并按特征名称的字母顺序进行排序，便于对比观察。\n",
    "#表头升序排序后赋值给headers1，sorted(headers[1:-1])不会影响headers原始内容。\n",
    "#注意定界范围，heaers[1:-1]表示从第二个数据取到倒数第二个数据。\n",
    "print(headers1)\n",
    "\n",
    "#测试函数：用于查看数据集中每一列特征值有几种类型，如：color特征有3种类型：'dark_green', 'black', 'light_white'\n",
    "def feature_kind(reader):\n",
    "    for i in range(8):\n",
    "    #del color_list[:]\n",
    "    #color_set = set(color_list)\n",
    "        color_list = []\n",
    "        j=i+1\n",
    "        wame_data.seek(0,0)   #调整数据指针到数据文件头\n",
    "        next(reader)          #读一次数据，使数据指针指向第一行数据\n",
    "        for row in reader:\n",
    "            color_list.append(row[j])\n",
    "        color_set = set(color_list)   #把列表转换为set集合，用于去重，可直观观察特征值的情况。\n",
    "        print(color_set)\n",
    "        print(len(color_set))\n",
    "    wame_data.seek(0,0)   #调整数据指针到数据文件头\n",
    "    next(reader)          #读一次数据，使数据指针指向第一行数据,恢复reader指针位置到函数调用前\n",
    "    \n",
    "feature_kind(reader)\n",
    "    \n",
    "#获得数据字典列表和标签表，以提供给DictVectorizer函数做特征向量变换的数据源。\n",
    "#数据字典列表的格式：[{特征1：值1，特征2：值1，...，特征8：值1},{特征1：值2，特征2：值2，...，特征8：值2},...]\n",
    "\n",
    "feature_list = []          #数据字典列表\n",
    "result_list = []           #标签表\n",
    "\n",
    "#把带数值类型的特征值转换为float类型，以便于在后续特征向量变换时保留数值特征。\n",
    "for row in reader:\n",
    "    result_list.append(row[-1])                  #生成标签表\n",
    "    float_list = [float(i) for i in row[7:9]]   #把数字形状的str类型元素转换为float类型，以便于在特征向量变换时不受变换影响。\n",
    "    com_list = row[1:7]+float_list\n",
    "    #print(com_list)\n",
    "    #feature_list.append(dict(zip(headers[1:-1],row[1:-1])))\n",
    "    feature_list.append(dict(zip(headers[1:-1],com_list)))  #特征名称和特征值组合成字典列表\n",
    "print(feature_list)\n",
    "\n",
    "#特征向量变换，把描述型特征值变换为独热编码（one-hot），数值型特征值保留原值。\n",
    "vec = DictVectorizer()          #把dict类型的list数据转换为numpy array\n",
    "dummyX = vec.fit_transform(feature_list).toarray()\n",
    "\n",
    "dummyY = result_list         #因为标签已经是二值化的，直接赋值即可\n",
    "#dummyY = preprocessing.LabelBinarizer().fit_transform(result_list)  #使用preprocessing.LabelBinarizer().fit_transform()对标签进行二值化处理\n",
    "#dummyY = [int(i) for i in result_list]     #因为标签已经是二值化的，元素转换为int类型，以便与str类型比较\n",
    "#经测试，二值化【0，1】标签是str型和int型效果相同，即使使用preprocessing.LabelBinarizer().fit_transform()处理的效果也相同。\n",
    "#因此，选择使用直接赋值方式\n",
    "\n",
    "print(dummyX)\n",
    "print(dummyY)\n",
    "\n",
    "#设计子函数，用于把one-hot特征向量变换为二进制代码\n",
    "def elementadd(code):\n",
    "    code_i_item = \"\"\n",
    "    for k in code:\n",
    "        code_i_item = code_i_item + k\n",
    "    return code_i_item\n",
    "\n",
    "#测试函数：生成数据特征值与向量代码的对应关系，获得每个特征值与向量代码的对应表（方便预测数据的设计），\n",
    "#如：['dark_green', '010'], ['black', '100'], ['light_white', '001']\n",
    "def featurevalues_code_get():\n",
    "    code_i = []\n",
    "    feature_dict_add = {}\n",
    "    feature_code_list = locals()\n",
    "    for m in range(6):                            #初始化feature_code_list+\"fm\"，8个特征减去2个数值特征。\n",
    "        feature_code_list[\"_f\" + str(m)] = []\n",
    "    #print(feature_code_list[\"_f\" + str(m)])\n",
    "    #特征名称-特征值字典列表排序，并删除特征值为数值的列表元素\n",
    "    for i in range(len(feature_list)):\n",
    "        feature_list_0_sort = sorted(feature_list[i].items(),key=lambda item:item[0])   #以特征名称对特征名称-特征值字典列表排序\n",
    "        del feature_list_0_sort[5]               #删除sugar_rate对应的键值对\n",
    "        del feature_list_0_sort[1]               #删除density对应的键值对\n",
    "        #print(feature_list_0_sort)\n",
    "\n",
    "    #遍历排序后的特征名称-特征值键值对数据，从中取出特征值并放入feature_i_item列表\n",
    "        feature_i_item = []\n",
    "        for k in feature_list_0_sort:       \n",
    "            feature_i_item.append(k[1])\n",
    "        print(feature_i_item)\n",
    "        #feature_i.append(feature_i_element)\n",
    "\n",
    "        #print(feature_i)\n",
    "\n",
    "        #对dummyX进行处理，删除特征值为数值的元素，把特征向量转换为二进制代码，并得到特征值与特征向量二进制代码的去重组合列表。\n",
    "        dummyX_i = list(dummyX[i])\n",
    "        del dummyX_i[3]\n",
    "        del dummyX_i[12]\n",
    "        dummyX_i_item = list(map(str,map(int,dummyX_i)))\n",
    "        #dummyX_i = list(map(str,map(int,dummyX[i])))\n",
    "        #del dummyX_i[3]\n",
    "        #del dummyX_i[12]\n",
    "        #print(dummyX_i)\n",
    "        code_i = []\n",
    "        for j in range(0,12,3):\n",
    "            code = dummyX_i_item[j:j+3]\n",
    "            code_i.append(elementadd(code))\n",
    "\n",
    "        code = dummyX_i_item[12:15]\n",
    "        code_i.append(elementadd(code))\n",
    "        code = dummyX_i_item[15:17]\n",
    "        code_i.append(elementadd(code))\n",
    "        print(code_i)\n",
    "        #print(dummyX_i_item)\n",
    "        for n in range(len(feature_i_item)):\n",
    "            if [feature_i_item[n],code_i[n]] not in feature_code_list[\"_f\" + str(n)]:\n",
    "                feature_code_list[\"_f\" + str(n)].append([feature_i_item[n],code_i[n]])\n",
    "\n",
    "    #显示特征名称和“特征值-代码”对\n",
    "    features = {\"0\":\"color\",\"1\":\"knocks\",\"2\":\"navel\",\"3\":\"root\",\"4\":\"texture\",\"5\":\"touch\"}\n",
    "    for m in range(len(feature_i_item)): \n",
    "        print(features[str(m)])\n",
    "        print(feature_code_list[\"_f\" + str(m)])\n",
    "\n",
    "featurevalues_code_get()\n",
    "\n",
    "#建立训练模型\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "#调用特征list和标签list进行训练\n",
    "clf = clf.fit(dummyX,dummyY)\n",
    "print(\"训练模型clf：\"+ \" \"+str(clf))  \n",
    "\n",
    "#生成决策树图\n",
    "import pydotplus\n",
    "dot_data = tree.export_graphviz(clf,feature_names=vec.get_feature_names(),filled=True,rounded=True,special_characters=True,out_file=None)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_pdf(\"watermelon.pdf\")\n",
    "\n",
    "A = ([[0,1,0,0.293,0,0,1,1,0,0,1,0,0,0.042,1,0,0,1,0]])  \n",
    "#颜色darkgreen,密度0.293,敲击light-heavily,瓜脐even（平），根蒂curl-up（卷），纹理blur（模糊），手感hard-smooth（硬滑）\n",
    "B = ([[0,0,1,0.593,0,0,1,1,0,0,1,0,0,0.042,1,0,0,1,0]])\n",
    "print(clf.predict(A))\n",
    "print(clf.predict_proba(A))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0']\n",
      "[[1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "B = ([[0,0,1,0.593,0,0,1,1,0,0,1,0,0,0.042,1,0,0,1,0]])\n",
    "print(clf.predict(B))\n",
    "print(clf.predict_proba(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='watermelon_4_3.csv' mode='rt' encoding='UTF-8'>\n",
      "<_csv.reader object at 0x7f0f5247cf98>\n",
      "['color', 'density', 'knocks', 'navel', 'root', 'sugar_ratio', 'texture', 'touch']\n"
     ]
    }
   ],
   "source": [
    "wame_data = open('watermelon_4_3.csv','rt')     #打开一个IO file对象\n",
    "reader = csv.reader(wame_data)                  #file对象wame_data作为参数传递给csv.reader方法，获得一个csv.reader对象\n",
    "print(wame_data)\n",
    "print(reader)\n",
    "headers = next(reader)\n",
    "headers = sorted(headers[1:-1])            #表头升序排序\n",
    "print(headers1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0,0],[1,1]]\n",
    "Y = [0,1]\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[3,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba([[2,2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
